\documentclass[11pt]{article}

% Guideline
% Abstract (short)
% Biography (~30 words for each author)   
% Keywords (up to six): 
% 2000 and 5000
% No limit on the number of figures

\usepackage[margin=1in]{geometry}
\usepackage{endfloat}

<<load-packages-options,cache=FALSE,echo=FALSE,message=FALSE,warning=FALSE>>=
library(ggplot2)
library(gdata)
library(reshape2)
library(plyr)
#Set some knitr options
opts_knit$set(progress = TRUE, verbose = TRUE)
opts_chunk$set(cache=FALSE, fig.width=16, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE)
@




\begin{document}

\title{Comparability and reproducibility of biomedical data}

\author{Raphael Gottardo and Yunda Yuang}

\date{\today}
\maketitle



% Outline: 
% 1.  There is an increasing need for comparability and reproducibility (C\&R) of biomedical data
% 2.	Overview of data generation process to identify each step that may influence C\&R
% 3.	Identify metrics to quantify C&R and their relation to accuracy and precision – recommend practices that increase C&R and recommend gold standard and positive/negative controls for meaningful research 
% 4.	Recommend analysis methods to factors that contribute to comparability and reproducibility 
% In the U.S. alone, biomedical research is a \$100-billion-year enterprise. This has stimulated an increasing availability of biomedical data, including those generated by traditional analytical technologies, as well as those from modern high-throughput “omics” platforms. Such a great amount of information provides researchers unprecedented opportunities to investigate scientific questions that otherwise could not be answered.  However, it also poses imperative concerns from the research community regarding the comparability and reproducibility of biomedical data. Can data generated from one source or laboratory be compared or pooled with those from another? Can data generated from one laboratory be reproduced in another? And how much do data-processing procedures play a role in such investigations? Many studies have been conducted to address one or multiple of these questions. In this report, we will systematically review various sources that contribute to the comparability and reproducibility of data, make recommendations on experiment designs that can increase comparability and reproducibility of data, and review analytical methods that address such an issue. For a related topic on reproducibility of study results, we direct readers to [ref: 1, 2, 3]. 
% 
% Let’s first look at a prototypical biomedical data generation process. As shown in Figure 1, the process of how information contained in a biological sample is quantified into numeric values for statistical /bioinformatical analysis can be roughly broken down into four steps.  In step 1 where biological samples are prepared to be measured, there are several factors that may influence the comparability and reproducibility of data, including common factors such as the specific type of measuring system (ref: xx), and the standard operating procedure (ref: xx) for biological sample preparation, experiment layout, and measurement, as well as other experimental conditions that are often not specified in the protocol. For example, xx (list studies that investigated effect of technician and time etc.). Therefore, in Step 1, to increase comparability and reproducibility of data, all these factors should be thought out and optimally controlled and standardized if possible. When factors such as technician and time are not feasible to be standardized across multiple labs, a measuring system should strive to minimize variations from these factors.  In step 2, raw information from an instrument is calibrated and quantified into numeric values. Xxx. Therefore, in step 2, standardized algorithms for these operations are recommended and, if possible, they are also implemented using the same software.  In Step 3, xxx 

\begin{abstract}
\end{abstract}

\section{Introduction}
Over the past two decades, the biomedical field has been transformed by the advent of new high throughput technologies including gene expression microarrays, protein arrays, flow cytometry and next generation sequencing. Because these technologies generate large high dimensional data from a single machine run, data management and analysis have become an integral part of any scientific experiment. 
In addition to the experimental protocol, data analysis contributes siginificantly to the reproducibility or non-reproducibility of an experiment or publication. Unfortunately, as of today, too many published studies remain un-reproducible due to the lack of sharing of data and/or computer code or scripts that can be used to reproduce the analysis. This lack of reproducibility has even gone has far as to stop a cancer clinical trial based on gene expression signatures that could not be reproduced by independent researchers. Should have the data and computer code been made available, the results of the study could have been invalidated more rapidly, which could have saved funding and avoid giving patients false hope. 

\section{Reproducibility of assay and primary data}
\subsection{Overview of data generation process and its impact on C\&R}
\subsection{Metrics to quantify C\&R}

\begin{figure}
\begin{center}
<<"data-for-reproducibility", fig.width=8,fig.height=6,dev=c('pdf', 'postscript'),echo=FALSE,dev.args=list(pointsize=16)>>=
# Set a seed for reproducibility
set.seed(6)

# True estimate
true.mean<-6
# Number of replicates
n<-100
biased.low.var<-rnorm(n,true.mean+3,sd=1)
biased.high.var<-rnorm(n,true.mean+2,sd=1.5)
unbiased.low.var<-rnorm(n,true.mean,sd=2)
unbiased.high.var<-rnorm(n,true.mean+3,sd=3)

data<-data.frame(Replicates=c(unbiased.low.var,unbiased.high.var,biased.low.var,biased.high.var),variance=c(rep("Low variance",n),rep("High variance",n),rep("Low variance",n),rep("High variance",n)),bias=c(rep("Unbiased",n),rep("Unbiased",n),rep("Biased",n),rep("Biased",n)),Protocol=c(rep("A",n),rep("B",n),rep("C",n),rep("D",n)),Exp=rep("x",4*n))

ggplot()+geom_boxplot(data=data,aes(y=Replicates,x=Exp,fill=Protocol,alpha=Protocol),outlier.size=0)+geom_abline(data=data,intercept=true.mean,slope=0,size=2,color="black",alpha=.5)+facet_grid(variance~bias)+theme_bw()+opts(panel.grid.major=theme_blank(),panel.grid.minor=theme_blank(),axis.text.y = theme_blank(),axis.text.x = theme_blank(), axis.title.x = theme_blank(), axis.ticks=theme_blank())+ annotate("text", 0, 6, label = "Truth", hjust = -0.5, vjust = -0.5)
@
\caption{Variance-Bias trade off. }
\end{center}
\end{figure}

\subsection{Correcting for experimental bias}
% Here we will talk about preprocessing such as normalization, batch effect correction, etc. 
\subsection{Standards and data sharing}


\section{Reproducibility of assay results and derived data}

Here we discuss some of the tools available to researchers to perform reproducible analysis and share processed data, computer code and final results. 

\subsection{Tools for reproducible analyses}

\subsection{Standards and code sharing}

\subsection{Authoring tools}

\section{Conclusion}


\end{document}