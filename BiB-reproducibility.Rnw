\documentclass[11pt]{article}

% Guidelines
% Abstract (short)
% Biography (~30 words for each author)   
% Keywords (up to six): 
% 2000 and 5000
% No limit on the number of figures

\usepackage[margin=1in]{geometry}
%\usepackage{endfloat}

<<load-packages-options,cache=FALSE,echo=FALSE,message=FALSE,warning=FALSE>>=
library(ggplot2)
library(gdata)
library(reshape2)
library(plyr)
#Set some knitr options
opts_knit$set(progress = TRUE, verbose = TRUE)
opts_chunk$set(cache=FALSE, fig.width=16, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE)
@




\begin{document}

\title{Comparability and reproducibility of biomedical data}

\author{Raphael Gottardo and Yunda Yuang}

\date{\today}
\maketitle



% Outline: 
% 1.  There is an increasing need for comparability and reproducibility (C\&R) of biomedical data
% 2.	Overview of data generation process to identify each step that may influence C\&R
% 3.	Identify metrics to quantify C&R and their relation to accuracy and precision – recommend practices that increase C&R and recommend gold standard and positive/negative controls for meaningful research 
% 4.	Recommend analysis methods to factors that contribute to comparability and reproducibility 
% In the U.S. alone, biomedical research is a \$100-billion-year enterprise. This has stimulated an increasing availability of biomedical data, including those generated by traditional analytical technologies, as well as those from modern high-throughput “omics” platforms. Such a great amount of information provides researchers unprecedented opportunities to investigate scientific questions that otherwise could not be answered.  However, it also poses imperative concerns from the research community regarding the comparability and reproducibility of biomedical data. Can data generated from one source or laboratory be compared or pooled with those from another? Can data generated from one laboratory be reproduced in another? And how much do data-processing procedures play a role in such investigations? Many studies have been conducted to address one or multiple of these questions. In this report, we will systematically review various sources that contribute to the comparability and reproducibility of data, make recommendations on experiment designs that can increase comparability and reproducibility of data, and review analytical methods that address such an issue. For a related topic on reproducibility of study results, we direct readers to [ref: 1, 2, 3]. 
% 
% Let’s first look at a prototypical biomedical data generation process. As shown in Figure 1, the process of how information contained in a biological sample is quantified into numeric values for statistical /bioinformatical analysis can be roughly broken down into four steps.  In step 1 where biological samples are prepared to be measured, there are several factors that may influence the comparability and reproducibility of data, including common factors such as the specific type of measuring system (ref: xx), and the standard operating procedure (ref: xx) for biological sample preparation, experiment layout, and measurement, as well as other experimental conditions that are often not specified in the protocol. For example, xx (list studies that investigated effect of technician and time etc.). Therefore, in Step 1, to increase comparability and reproducibility of data, all these factors should be thought out and optimally controlled and standardized if possible. When factors such as technician and time are not feasible to be standardized across multiple labs, a measuring system should strive to minimize variations from these factors.  In step 2, raw information from an instrument is calibrated and quantified into numeric values. Xxx. Therefore, in step 2, standardized algorithms for these operations are recommended and, if possible, they are also implemented using the same software.  In Step 3, xxx 

\begin{abstract}
\end{abstract}

\section{Introduction}

% Some text to motivate the reproducibility of data analysis
Over the past two decades, the biomedical field has been transformed by the advent of new high throughput technologies including gene expression microarrays, protein arrays, flow cytometry and next generation sequencing. Because these technologies generate large high dimensional data from a single machine run, data management and analysis have become an integral part of any scientific experiment. 
In addition to the experimental protocol, data analysis contributes significantly to the reproducibility or non-reproducibility of an experiment or publication. Unfortunately, as of today, too many published studies remain irreproducible due to the lack of sharing of data and/or computer code or scripts that can be used to reproduce the analysis. This lack of reproducibility has even gone as far as to stop a cancer clinical trial based on gene expression signatures that could not be reproduced by independent researchers. Should have the data and computer code been made available, the results of the study could have been invalidated more rapidly, which could have saved funding and avoided giving patients false hope. Fortunately, over the past decade computers, software tools and online resources have drastically improved to the point that it is easier than ever to share data, code and construct fully reproducible data analysis pipelines. 

In this paper we review some of the fundamental issues involved in the reproducibility and comparability of biomedical data going from assay standardization to reproducible data analysis. This paper is not meant to be an exhaustive review of all possible assays and problems but rather to select a few concrete examples and present some thoughts and solutions towards the overall C\&R concept. 
The paper is organized as follows 

\section{Reproducibility of assay and primary data}
\subsection{Overview of data generation process and its impact on C\&R}
Let’s first look at a prototypical biomedical data generation process. As shown in Figure 1, the process can be roughly broken down into four components. of how information contained in a biological sample is quantified into numeric values for data analysis  In step 1 where biological samples are prepared to be measured, there are several factors that may influence the comparability and reproducibility of data, including common factors such as the specific type of measuring system (ref: xx), and the standard operating procedure (ref: xx) for biological sample preparation, experiment layout, and measurement, as well as other experimental conditions that are often not specified in the protocol. For example, xx (list studies that investigated effect of technician and time etc.). Therefore, in Step 1, to increase comparability and reproducibility of data, all these factors should be thought out and optimally controlled and standardized if possible. When factors such as technician and time are not feasible to be standardized across multiple labs, a measuring system should strive to minimize variations from these factors.  In step 2, raw information from an instrument is calibrated and quantified into numeric values. Xxx. Therefore, in step 2, standardized algorithms for these operations are recommended and, if possible, they are also implemented using the same software.  In Step 3, xxx 

\subsection{Metrics to quantify C\&R}

\begin{figure}
\begin{center}
<<"data-for-reproducibility", fig.width=8,fig.height=6,dev=c('pdf', 'postscript'),echo=FALSE,dev.args=list(pointsize=16)>>=
# Set a seed for reproducibility
set.seed(6)

# True estimate
true.mean<-6
# Number of replicates
n<-100
biased.low.var<-rnorm(n,true.mean+3,sd=1)
biased.high.var<-rnorm(n,true.mean+2,sd=1.5)
unbiased.low.var<-rnorm(n,true.mean,sd=2)
unbiased.high.var<-rnorm(n,true.mean+3,sd=3)

data<-data.frame(Replicates=c(unbiased.low.var,unbiased.high.var,biased.low.var,biased.high.var),variance=c(rep("Low variance",n),rep("High variance",n),rep("Low variance",n),rep("High variance",n)),bias=c(rep("Unbiased",n),rep("Unbiased",n),rep("Biased",n),rep("Biased",n)),Protocol=c(rep("A",n),rep("B",n),rep("C",n),rep("D",n)),Exp=rep("x",4*n))

ggplot()+geom_boxplot(data=data,aes(y=Replicates,x=Exp,fill=Protocol,alpha=Protocol),outlier.size=0)+geom_abline(data=data,intercept=true.mean,slope=0,size=2,color="black",alpha=.5)+facet_grid(variance~bias)+theme_bw()+opts(panel.grid.major=theme_blank(),panel.grid.minor=theme_blank(),axis.text.y = theme_blank(),axis.text.x = theme_blank(), axis.title.x = theme_blank(), axis.ticks=theme_blank())+ annotate("text", 0, 6, label = "Truth", hjust = -0.5, vjust = -0.5)
@
\caption{Variance-Bias trade off. }

\end{center}
\end{figure}

\subsection{Correcting for experimental bias}
% Here we will talk about preprocessing such as normalization, batch effect correction, etc. 
% Talk about preprocessing for variance-bias (e.g. Microarrays and background subtraction)
\subsection{Standards and data sharing}


\section{Reproducibility of assay results and derived data}

Here we discuss some of the tools available to researchers to perform reproducible analysis and share processed data, computer code and final results. 

\subsection{Tools for reproducible analyses}
% R and Bioconductor
% RStudio
% BioPerl, BioPython
% GenomeSpace
% LabKey
\subsection{Standards and code sharing}
In the same fashion that experimental protocols need to be published in order for an experiment to be reproduced, computer code, software and data should also be published along with the results of a data analysis. Ideally, software would be open source and computer code would be well package and standardize to facilitate exchange and usability. 
% GitHub
% RStudio
% Open Source
\subsection{Authoring tools}
% Sweave, knitr, Rstudio, openoffice, pandoc
% GenePattern and Word plugin


Several tools have been proposed to automatically incorporate 
reproducible data analysis pipelines or computer code into documents.
An example is the GenePattern Word plugin that can be used to embed analysis pipelines in a document and rerun them on any GenePattern server from the Word application. 
Another example that is popular among statisticians and bioinformatics is the Sweave literate language that allows one to create dynamic reports by embedding R code in latex documents. This is also our preferred approach because it is open source and does not depend on propriety software. In addition, recent software development such as RStudio and knitr made working with Sweave even more accessible, which should reduce the learning curve for most users. In fact, this article was written using the Sweave language and processed using RStudio. 
Ideally, all material including the Sweave source file, computer code and data, which Gentleman refers to as a compendium, would be made available along with the final version of the manuscript and be open access, allowing anyone to reproduce the results or identify potential problems in the analysis. This openness should further improve the impact of open access papers and journals over non-open access journals by giving more credibility to the published results. Unfortunately, currently very few journals are pushing for reproducibility and even less have clear reproducibility policies. An example of a journal moving in the right direction is Biostatistics, for which one of us is associate editor. Biostatistics now has a reproducility guideline and is now working with authors towards making sure that published results are reproducible given that data and code are provided (as described in the guileline). When data and code are provided, and results are reproducible, the article is marked with an R. 

\subsection{Open science}

\section{Conclusion}


\end{document}